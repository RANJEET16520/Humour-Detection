{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "xlnet_Training.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "886cd988bcf94ebc92e7438d031f515e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c58276e8e5f64dbc9093104a986d30b8",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a19401c45e314fd09a86823a5a253051",
              "IPY_MODEL_585611b34ae244a883975ba017223451"
            ]
          }
        },
        "c58276e8e5f64dbc9093104a986d30b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a19401c45e314fd09a86823a5a253051": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a18bc8bb7c2f4314940c15a2dd995630",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 798011,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 798011,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_077deba028e64d93a4e74b36b5300b7b"
          }
        },
        "585611b34ae244a883975ba017223451": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ef9681bf3b234ed388495bdb7875e079",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 798k/798k [00:00&lt;00:00, 1.73MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_991da577c8d34a688e2837776d7d8eee"
          }
        },
        "a18bc8bb7c2f4314940c15a2dd995630": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "077deba028e64d93a4e74b36b5300b7b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ef9681bf3b234ed388495bdb7875e079": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "991da577c8d34a688e2837776d7d8eee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b3e05239bc2d456bbbb1eecdcf42dda9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_421ac4013f6343d5a6ae74e36011cc77",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_28f39bead17e40f9abfc05f820028ea2",
              "IPY_MODEL_7b5c5ad4baea4087b9f851552e3f22f7"
            ]
          }
        },
        "421ac4013f6343d5a6ae74e36011cc77": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "28f39bead17e40f9abfc05f820028ea2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b304e30b0e58451cb7cf5131f9874e28",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 760,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 760,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a2d284d115b74ee08ba56b33c6f2d841"
          }
        },
        "7b5c5ad4baea4087b9f851552e3f22f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d8677dabede44c18a8fcbec6900039ce",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 760/760 [00:29&lt;00:00, 25.6B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ecc0c1b3c0d846f2aa7e7e22021cc8f8"
          }
        },
        "b304e30b0e58451cb7cf5131f9874e28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a2d284d115b74ee08ba56b33c6f2d841": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d8677dabede44c18a8fcbec6900039ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ecc0c1b3c0d846f2aa7e7e22021cc8f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2b910e363acb4f739b48daead2eea64f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_18d090a3fa7448bb83670b60d54e8bfa",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_034d3dc557544f03b8e30a6d6ab755f0",
              "IPY_MODEL_20b7c4b41a8b42eaa8f7a06dbcc7cdce"
            ]
          }
        },
        "18d090a3fa7448bb83670b60d54e8bfa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "034d3dc557544f03b8e30a6d6ab755f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2ddf47d84ac948d5a86793b99ddf75d8",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 467042463,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 467042463,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7d85cc6324ce47eeaa73012f279c97ff"
          }
        },
        "20b7c4b41a8b42eaa8f7a06dbcc7cdce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d1200bf2bbbf4fdb9d97098e1147ebfb",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 467M/467M [00:10&lt;00:00, 45.6MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c79979acd68547d5b78f5d0ff4fd3e69"
          }
        },
        "2ddf47d84ac948d5a86793b99ddf75d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7d85cc6324ce47eeaa73012f279c97ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d1200bf2bbbf4fdb9d97098e1147ebfb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c79979acd68547d5b78f5d0ff4fd3e69": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RANJEET16520/Humour-Detection/blob/master/xlnet_Training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4Q1SiJWPG7B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "95155322-d824-48f3-d5c9-23a1b82eba32"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BO4ZL084AzIK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "72a50428-7d7f-4b4d-fbfb-9146fbbc35dd"
      },
      "source": [
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        " \n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        " \n",
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isn’t guaranteed\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        "    process = psutil.Process(os.getpid())\n",
        "    print(\"Gen RAM Free: \" + humanize.naturalsize(psutil.virtual_memory().available), \" |     Proc size: \" + humanize.naturalsize(process.memory_info().rss))\n",
        "    print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total     {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "printm()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gputil\n",
            "  Downloading https://files.pythonhosted.org/packages/ed/0e/5c61eedde9f6c87713e89d794f01e378cfd9565847d4576fa627d758c554/GPUtil-1.4.0.tar.gz\n",
            "Building wheels for collected packages: gputil\n",
            "  Building wheel for gputil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gputil: filename=GPUtil-1.4.0-cp36-none-any.whl size=7413 sha256=0d7ba69142069993b7cda5a8da99dc4faf8f293264ef1ac84e1e1fe7594b2615\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/77/07/80562de4bb0786e5ea186911a2c831fdd0018bda69beab71fd\n",
            "Successfully built gputil\n",
            "Installing collected packages: gputil\n",
            "Successfully installed gputil-1.4.0\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (5.4.8)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.6/dist-packages (0.5.1)\n",
            "Gen RAM Free: 12.7 GB  |     Proc size: 159.4 MB\n",
            "GPU RAM Free: 16280MB | Used: 0MB | Util   0% | Total     16280MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NdeHA7VqsFD1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "77244691-140a-4e0a-e87f-d37b87a67259"
      },
      "source": [
        "!pip install transformers\n",
        "!pip install pytorch_transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/3c/91ed8f5c4e7ef3227b4119200fc0ed4b4fd965b1f0172021c25701087825/transformers-3.0.2-py3-none-any.whl (769kB)\n",
            "\r\u001b[K     |▍                               | 10kB 27.8MB/s eta 0:00:01\r\u001b[K     |▉                               | 20kB 2.9MB/s eta 0:00:01\r\u001b[K     |█▎                              | 30kB 3.8MB/s eta 0:00:01\r\u001b[K     |█▊                              | 40kB 4.2MB/s eta 0:00:01\r\u001b[K     |██▏                             | 51kB 3.4MB/s eta 0:00:01\r\u001b[K     |██▋                             | 61kB 3.7MB/s eta 0:00:01\r\u001b[K     |███                             | 71kB 4.2MB/s eta 0:00:01\r\u001b[K     |███▍                            | 81kB 4.4MB/s eta 0:00:01\r\u001b[K     |███▉                            | 92kB 4.7MB/s eta 0:00:01\r\u001b[K     |████▎                           | 102kB 4.6MB/s eta 0:00:01\r\u001b[K     |████▊                           | 112kB 4.6MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 122kB 4.6MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 133kB 4.6MB/s eta 0:00:01\r\u001b[K     |██████                          | 143kB 4.6MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 153kB 4.6MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 163kB 4.6MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 174kB 4.6MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 184kB 4.6MB/s eta 0:00:01\r\u001b[K     |████████                        | 194kB 4.6MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 204kB 4.6MB/s eta 0:00:01\r\u001b[K     |█████████                       | 215kB 4.6MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 225kB 4.6MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 235kB 4.6MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 245kB 4.6MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 256kB 4.6MB/s eta 0:00:01\r\u001b[K     |███████████                     | 266kB 4.6MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 276kB 4.6MB/s eta 0:00:01\r\u001b[K     |████████████                    | 286kB 4.6MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 296kB 4.6MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 307kB 4.6MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 317kB 4.6MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 327kB 4.6MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 337kB 4.6MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 348kB 4.6MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 358kB 4.6MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 368kB 4.6MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 378kB 4.6MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 389kB 4.6MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 399kB 4.6MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 409kB 4.6MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 419kB 4.6MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 430kB 4.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 440kB 4.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 450kB 4.6MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 460kB 4.6MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 471kB 4.6MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 481kB 4.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 491kB 4.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 501kB 4.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 512kB 4.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 522kB 4.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 532kB 4.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 542kB 4.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 552kB 4.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 563kB 4.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 573kB 4.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 583kB 4.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 593kB 4.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 604kB 4.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 614kB 4.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 624kB 4.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 634kB 4.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 645kB 4.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 655kB 4.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 665kB 4.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 675kB 4.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 686kB 4.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 696kB 4.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 706kB 4.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 716kB 4.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 727kB 4.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 737kB 4.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 747kB 4.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 757kB 4.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 768kB 4.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 778kB 4.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Collecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 20.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 35.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Collecting tokenizers==0.8.1.rc1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/d0/30d5f8d221a0ed981a186c8eb986ce1c94e3a6e87f994eae9f4aa5250217/tokenizers-0.8.1rc1-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 42.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.15.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.9)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=3cb912351f93f702900ee1043131700acfbd960829ee451d88ea5a3856b977f6\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sentencepiece, sacremoses, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.8.1rc1 transformers-3.0.2\n",
            "Collecting pytorch_transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/b7/d3d18008a67e0b968d1ab93ad444fc05699403fa662f634b2f2c318a508b/pytorch_transformers-1.2.0-py3-none-any.whl (176kB)\n",
            "\u001b[K     |████████████████████████████████| 184kB 6.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from pytorch_transformers) (1.5.1+cu101)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch_transformers) (2.23.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch_transformers) (1.14.9)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch_transformers) (4.41.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch_transformers) (1.18.5)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch_transformers) (2019.12.20)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from pytorch_transformers) (0.0.43)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from pytorch_transformers) (0.1.91)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.0.0->pytorch_transformers) (0.16.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_transformers) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_transformers) (2.9)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_transformers) (0.3.3)\n",
            "Requirement already satisfied: botocore<1.18.0,>=1.17.9 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_transformers) (1.17.9)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_transformers) (0.10.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch_transformers) (1.12.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch_transformers) (0.15.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch_transformers) (7.1.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.9->boto3->pytorch_transformers) (2.8.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.9->boto3->pytorch_transformers) (0.15.2)\n",
            "Installing collected packages: pytorch-transformers\n",
            "Successfully installed pytorch-transformers-1.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZ1ddRgaPCGV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "8cd3c62b-1d3d-466f-9ad6-d935e556eda0"
      },
      "source": [
        "import os\n",
        "import math\n",
        "import glob\n",
        "import logging\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import torch\n",
        "from torch.nn import BCEWithLogitsLoss\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import XLNetTokenizer, XLNetModel, XLNetLMHeadModel, XLNetConfig, XLNetForSequenceClassification\n",
        "from pytorch_transformers import AdamW, WarmupLinearSchedule\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm, trange\n",
        "from sklearn.metrics import mean_squared_error, matthews_corrcoef, confusion_matrix"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n",
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rx5hA9apvAJG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "c9228fcf-aad1-462e-dbb7-86a1d1a09065"
      },
      "source": [
        "print(\"GPU Available: {}\".format(torch.cuda.is_available()))\n",
        "n_gpu = torch.cuda.device_count()\n",
        "print(\"Number of GPU Available: {}\".format(n_gpu))\n",
        "print(\"GPU: {}\".format(torch.cuda.get_device_name(0)))\n",
        "print(\"Current Device is {}\".format('GPU' if torch.cuda.current_device()==0 else 'CPU'))\n",
        "torch.cuda.set_device(0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU Available: True\n",
            "Number of GPU Available: 1\n",
            "GPU: Tesla P100-PCIE-16GB\n",
            "Current Device is GPU\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xiIlca9evRhZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "884b735c-1779-40f2-e61a-1f1d56ffc6f4"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6o1a5Cevo7WH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5d28c86c-d0d1-45ba-b074-f52096f6b173"
      },
      "source": [
        "cd drive/My Drive/Colab Notebooks/apex"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1_A25iC8PhwLE9n1Xyst3s1mB57L9kbs3/apex\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6tQIYqJ_o9Gi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2f644efa-2c47-4b5e-c76d-bd5ab159ed6b"
      },
      "source": [
        "! python setup.py install --cuda_ext --cpp_ext"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "torch.__version__  = 1.5.1+cu101\n",
            "\n",
            "\n",
            "setup.py:51: UserWarning: Option --pyprof not specified. Not installing PyProf dependencies!\n",
            "  warnings.warn(\"Option --pyprof not specified. Not installing PyProf dependencies!\")\n",
            "\n",
            "Compiling cuda extensions with\n",
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2019 NVIDIA Corporation\n",
            "Built on Sun_Jul_28_19:07:16_PDT_2019\n",
            "Cuda compilation tools, release 10.1, V10.1.243\n",
            "from /usr/local/cuda/bin\n",
            "\n",
            "running install\n",
            "running bdist_egg\n",
            "running egg_info\n",
            "writing apex.egg-info/PKG-INFO\n",
            "writing dependency_links to apex.egg-info/dependency_links.txt\n",
            "writing top-level names to apex.egg-info/top_level.txt\n",
            "/usr/local/lib/python3.6/dist-packages/torch/utils/cpp_extension.py:305: UserWarning: Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\n",
            "  warnings.warn(msg.format('we could not find ninja.'))\n",
            "writing manifest file 'apex.egg-info/SOURCES.txt'\n",
            "installing library code to build/bdist.linux-x86_64/egg\n",
            "running install_lib\n",
            "running build_py\n",
            "running build_ext\n",
            "creating build/bdist.linux-x86_64/egg\n",
            "creating build/bdist.linux-x86_64/egg/apex\n",
            "copying build/lib.linux-x86_64-3.6/apex/__init__.py -> build/bdist.linux-x86_64/egg/apex\n",
            "creating build/bdist.linux-x86_64/egg/apex/RNN\n",
            "copying build/lib.linux-x86_64-3.6/apex/RNN/__init__.py -> build/bdist.linux-x86_64/egg/apex/RNN\n",
            "copying build/lib.linux-x86_64-3.6/apex/RNN/RNNBackend.py -> build/bdist.linux-x86_64/egg/apex/RNN\n",
            "copying build/lib.linux-x86_64-3.6/apex/RNN/cells.py -> build/bdist.linux-x86_64/egg/apex/RNN\n",
            "copying build/lib.linux-x86_64-3.6/apex/RNN/models.py -> build/bdist.linux-x86_64/egg/apex/RNN\n",
            "creating build/bdist.linux-x86_64/egg/apex/amp\n",
            "copying build/lib.linux-x86_64-3.6/apex/amp/_initialize.py -> build/bdist.linux-x86_64/egg/apex/amp\n",
            "copying build/lib.linux-x86_64-3.6/apex/amp/rnn_compat.py -> build/bdist.linux-x86_64/egg/apex/amp\n",
            "copying build/lib.linux-x86_64-3.6/apex/amp/compat.py -> build/bdist.linux-x86_64/egg/apex/amp\n",
            "copying build/lib.linux-x86_64-3.6/apex/amp/amp.py -> build/bdist.linux-x86_64/egg/apex/amp\n",
            "copying build/lib.linux-x86_64-3.6/apex/amp/_process_optimizer.py -> build/bdist.linux-x86_64/egg/apex/amp\n",
            "copying build/lib.linux-x86_64-3.6/apex/amp/handle.py -> build/bdist.linux-x86_64/egg/apex/amp\n",
            "copying build/lib.linux-x86_64-3.6/apex/amp/_amp_state.py -> build/bdist.linux-x86_64/egg/apex/amp\n",
            "copying build/lib.linux-x86_64-3.6/apex/amp/scaler.py -> build/bdist.linux-x86_64/egg/apex/amp\n",
            "copying build/lib.linux-x86_64-3.6/apex/amp/frontend.py -> build/bdist.linux-x86_64/egg/apex/amp\n",
            "copying build/lib.linux-x86_64-3.6/apex/amp/utils.py -> build/bdist.linux-x86_64/egg/apex/amp\n",
            "copying build/lib.linux-x86_64-3.6/apex/amp/opt.py -> build/bdist.linux-x86_64/egg/apex/amp\n",
            "copying build/lib.linux-x86_64-3.6/apex/amp/__version__.py -> build/bdist.linux-x86_64/egg/apex/amp\n",
            "copying build/lib.linux-x86_64-3.6/apex/amp/__init__.py -> build/bdist.linux-x86_64/egg/apex/amp\n",
            "copying build/lib.linux-x86_64-3.6/apex/amp/wrap.py -> build/bdist.linux-x86_64/egg/apex/amp\n",
            "creating build/bdist.linux-x86_64/egg/apex/amp/lists\n",
            "copying build/lib.linux-x86_64-3.6/apex/amp/lists/__init__.py -> build/bdist.linux-x86_64/egg/apex/amp/lists\n",
            "copying build/lib.linux-x86_64-3.6/apex/amp/lists/tensor_overrides.py -> build/bdist.linux-x86_64/egg/apex/amp/lists\n",
            "copying build/lib.linux-x86_64-3.6/apex/amp/lists/torch_overrides.py -> build/bdist.linux-x86_64/egg/apex/amp/lists\n",
            "copying build/lib.linux-x86_64-3.6/apex/amp/lists/functional_overrides.py -> build/bdist.linux-x86_64/egg/apex/amp/lists\n",
            "creating build/bdist.linux-x86_64/egg/apex/contrib\n",
            "copying build/lib.linux-x86_64-3.6/apex/contrib/__init__.py -> build/bdist.linux-x86_64/egg/apex/contrib\n",
            "creating build/bdist.linux-x86_64/egg/apex/contrib/groupbn\n",
            "copying build/lib.linux-x86_64-3.6/apex/contrib/groupbn/batch_norm.py -> build/bdist.linux-x86_64/egg/apex/contrib/groupbn\n",
            "copying build/lib.linux-x86_64-3.6/apex/contrib/groupbn/__init__.py -> build/bdist.linux-x86_64/egg/apex/contrib/groupbn\n",
            "creating build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn\n",
            "copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/__init__.py -> build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn\n",
            "copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/encdec_multihead_attn_func.py -> build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn\n",
            "copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/fast_self_multihead_attn_func.py -> build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn\n",
            "copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py -> build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn\n",
            "copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/self_multihead_attn.py -> build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn\n",
            "copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py -> build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn\n",
            "copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/mask_softmax_dropout_func.py -> build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn\n",
            "copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py -> build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn\n",
            "copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/self_multihead_attn_func.py -> build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn\n",
            "copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/encdec_multihead_attn.py -> build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn\n",
            "creating build/bdist.linux-x86_64/egg/apex/contrib/optimizers\n",
            "copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/distributed_fused_lamb.py -> build/bdist.linux-x86_64/egg/apex/contrib/optimizers\n",
            "copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/__init__.py -> build/bdist.linux-x86_64/egg/apex/contrib/optimizers\n",
            "copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/distributed_fused_adam_v2.py -> build/bdist.linux-x86_64/egg/apex/contrib/optimizers\n",
            "copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/fused_adam.py -> build/bdist.linux-x86_64/egg/apex/contrib/optimizers\n",
            "copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/distributed_fused_adam_v3.py -> build/bdist.linux-x86_64/egg/apex/contrib/optimizers\n",
            "copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/distributed_fused_adam.py -> build/bdist.linux-x86_64/egg/apex/contrib/optimizers\n",
            "copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/fused_lamb.py -> build/bdist.linux-x86_64/egg/apex/contrib/optimizers\n",
            "copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/fp16_optimizer.py -> build/bdist.linux-x86_64/egg/apex/contrib/optimizers\n",
            "copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/fused_sgd.py -> build/bdist.linux-x86_64/egg/apex/contrib/optimizers\n",
            "creating build/bdist.linux-x86_64/egg/apex/contrib/sparsity\n",
            "copying build/lib.linux-x86_64-3.6/apex/contrib/sparsity/__init__.py -> build/bdist.linux-x86_64/egg/apex/contrib/sparsity\n",
            "copying build/lib.linux-x86_64-3.6/apex/contrib/sparsity/asp.py -> build/bdist.linux-x86_64/egg/apex/contrib/sparsity\n",
            "copying build/lib.linux-x86_64-3.6/apex/contrib/sparsity/sparse_masklib.py -> build/bdist.linux-x86_64/egg/apex/contrib/sparsity\n",
            "creating build/bdist.linux-x86_64/egg/apex/contrib/xentropy\n",
            "copying build/lib.linux-x86_64-3.6/apex/contrib/xentropy/softmax_xentropy.py -> build/bdist.linux-x86_64/egg/apex/contrib/xentropy\n",
            "copying build/lib.linux-x86_64-3.6/apex/contrib/xentropy/__init__.py -> build/bdist.linux-x86_64/egg/apex/contrib/xentropy\n",
            "creating build/bdist.linux-x86_64/egg/apex/fp16_utils\n",
            "copying build/lib.linux-x86_64-3.6/apex/fp16_utils/fp16_optimizer.py -> build/bdist.linux-x86_64/egg/apex/fp16_utils\n",
            "copying build/lib.linux-x86_64-3.6/apex/fp16_utils/fp16util.py -> build/bdist.linux-x86_64/egg/apex/fp16_utils\n",
            "copying build/lib.linux-x86_64-3.6/apex/fp16_utils/loss_scaler.py -> build/bdist.linux-x86_64/egg/apex/fp16_utils\n",
            "copying build/lib.linux-x86_64-3.6/apex/fp16_utils/__init__.py -> build/bdist.linux-x86_64/egg/apex/fp16_utils\n",
            "creating build/bdist.linux-x86_64/egg/apex/mlp\n",
            "copying build/lib.linux-x86_64-3.6/apex/mlp/mlp.py -> build/bdist.linux-x86_64/egg/apex/mlp\n",
            "copying build/lib.linux-x86_64-3.6/apex/mlp/__init__.py -> build/bdist.linux-x86_64/egg/apex/mlp\n",
            "creating build/bdist.linux-x86_64/egg/apex/multi_tensor_apply\n",
            "copying build/lib.linux-x86_64-3.6/apex/multi_tensor_apply/__init__.py -> build/bdist.linux-x86_64/egg/apex/multi_tensor_apply\n",
            "copying build/lib.linux-x86_64-3.6/apex/multi_tensor_apply/multi_tensor_apply.py -> build/bdist.linux-x86_64/egg/apex/multi_tensor_apply\n",
            "creating build/bdist.linux-x86_64/egg/apex/normalization\n",
            "copying build/lib.linux-x86_64-3.6/apex/normalization/fused_layer_norm.py -> build/bdist.linux-x86_64/egg/apex/normalization\n",
            "copying build/lib.linux-x86_64-3.6/apex/normalization/__init__.py -> build/bdist.linux-x86_64/egg/apex/normalization\n",
            "creating build/bdist.linux-x86_64/egg/apex/optimizers\n",
            "copying build/lib.linux-x86_64-3.6/apex/optimizers/fused_adagrad.py -> build/bdist.linux-x86_64/egg/apex/optimizers\n",
            "copying build/lib.linux-x86_64-3.6/apex/optimizers/fused_lamb.py -> build/bdist.linux-x86_64/egg/apex/optimizers\n",
            "copying build/lib.linux-x86_64-3.6/apex/optimizers/fused_sgd.py -> build/bdist.linux-x86_64/egg/apex/optimizers\n",
            "copying build/lib.linux-x86_64-3.6/apex/optimizers/fused_novograd.py -> build/bdist.linux-x86_64/egg/apex/optimizers\n",
            "copying build/lib.linux-x86_64-3.6/apex/optimizers/fused_adam.py -> build/bdist.linux-x86_64/egg/apex/optimizers\n",
            "copying build/lib.linux-x86_64-3.6/apex/optimizers/__init__.py -> build/bdist.linux-x86_64/egg/apex/optimizers\n",
            "creating build/bdist.linux-x86_64/egg/apex/parallel\n",
            "copying build/lib.linux-x86_64-3.6/apex/parallel/multiproc.py -> build/bdist.linux-x86_64/egg/apex/parallel\n",
            "copying build/lib.linux-x86_64-3.6/apex/parallel/optimized_sync_batchnorm.py -> build/bdist.linux-x86_64/egg/apex/parallel\n",
            "copying build/lib.linux-x86_64-3.6/apex/parallel/__init__.py -> build/bdist.linux-x86_64/egg/apex/parallel\n",
            "copying build/lib.linux-x86_64-3.6/apex/parallel/sync_batchnorm.py -> build/bdist.linux-x86_64/egg/apex/parallel\n",
            "copying build/lib.linux-x86_64-3.6/apex/parallel/optimized_sync_batchnorm_kernel.py -> build/bdist.linux-x86_64/egg/apex/parallel\n",
            "copying build/lib.linux-x86_64-3.6/apex/parallel/LARC.py -> build/bdist.linux-x86_64/egg/apex/parallel\n",
            "copying build/lib.linux-x86_64-3.6/apex/parallel/sync_batchnorm_kernel.py -> build/bdist.linux-x86_64/egg/apex/parallel\n",
            "copying build/lib.linux-x86_64-3.6/apex/parallel/distributed.py -> build/bdist.linux-x86_64/egg/apex/parallel\n",
            "creating build/bdist.linux-x86_64/egg/apex/pyprof\n",
            "copying build/lib.linux-x86_64-3.6/apex/pyprof/__init__.py -> build/bdist.linux-x86_64/egg/apex/pyprof\n",
            "creating build/bdist.linux-x86_64/egg/apex/pyprof/nvtx\n",
            "copying build/lib.linux-x86_64-3.6/apex/pyprof/nvtx/nvmarker.py -> build/bdist.linux-x86_64/egg/apex/pyprof/nvtx\n",
            "copying build/lib.linux-x86_64-3.6/apex/pyprof/nvtx/__init__.py -> build/bdist.linux-x86_64/egg/apex/pyprof/nvtx\n",
            "creating build/bdist.linux-x86_64/egg/apex/pyprof/parse\n",
            "copying build/lib.linux-x86_64-3.6/apex/pyprof/parse/__init__.py -> build/bdist.linux-x86_64/egg/apex/pyprof/parse\n",
            "copying build/lib.linux-x86_64-3.6/apex/pyprof/parse/nvvp.py -> build/bdist.linux-x86_64/egg/apex/pyprof/parse\n",
            "copying build/lib.linux-x86_64-3.6/apex/pyprof/parse/db.py -> build/bdist.linux-x86_64/egg/apex/pyprof/parse\n",
            "copying build/lib.linux-x86_64-3.6/apex/pyprof/parse/__main__.py -> build/bdist.linux-x86_64/egg/apex/pyprof/parse\n",
            "copying build/lib.linux-x86_64-3.6/apex/pyprof/parse/kernel.py -> build/bdist.linux-x86_64/egg/apex/pyprof/parse\n",
            "copying build/lib.linux-x86_64-3.6/apex/pyprof/parse/parse.py -> build/bdist.linux-x86_64/egg/apex/pyprof/parse\n",
            "creating build/bdist.linux-x86_64/egg/apex/pyprof/prof\n",
            "copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/conv.py -> build/bdist.linux-x86_64/egg/apex/pyprof/prof\n",
            "copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/__init__.py -> build/bdist.linux-x86_64/egg/apex/pyprof/prof\n",
            "copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/activation.py -> build/bdist.linux-x86_64/egg/apex/pyprof/prof\n",
            "copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/blas.py -> build/bdist.linux-x86_64/egg/apex/pyprof/prof\n",
            "copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/base.py -> build/bdist.linux-x86_64/egg/apex/pyprof/prof\n",
            "copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/__main__.py -> build/bdist.linux-x86_64/egg/apex/pyprof/prof\n",
            "copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/normalization.py -> build/bdist.linux-x86_64/egg/apex/pyprof/prof\n",
            "copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/index_slice_join_mutate.py -> build/bdist.linux-x86_64/egg/apex/pyprof/prof\n",
            "copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/usage.py -> build/bdist.linux-x86_64/egg/apex/pyprof/prof\n",
            "copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/pooling.py -> build/bdist.linux-x86_64/egg/apex/pyprof/prof\n",
            "copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/convert.py -> build/bdist.linux-x86_64/egg/apex/pyprof/prof\n",
            "copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/data.py -> build/bdist.linux-x86_64/egg/apex/pyprof/prof\n",
            "copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/linear.py -> build/bdist.linux-x86_64/egg/apex/pyprof/prof\n",
            "copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/pointwise.py -> build/bdist.linux-x86_64/egg/apex/pyprof/prof\n",
            "copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/embedding.py -> build/bdist.linux-x86_64/egg/apex/pyprof/prof\n",
            "copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/reduction.py -> build/bdist.linux-x86_64/egg/apex/pyprof/prof\n",
            "copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/optim.py -> build/bdist.linux-x86_64/egg/apex/pyprof/prof\n",
            "copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/utility.py -> build/bdist.linux-x86_64/egg/apex/pyprof/prof\n",
            "copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/recurrentCell.py -> build/bdist.linux-x86_64/egg/apex/pyprof/prof\n",
            "copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/output.py -> build/bdist.linux-x86_64/egg/apex/pyprof/prof\n",
            "copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/softmax.py -> build/bdist.linux-x86_64/egg/apex/pyprof/prof\n",
            "copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/dropout.py -> build/bdist.linux-x86_64/egg/apex/pyprof/prof\n",
            "copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/randomSample.py -> build/bdist.linux-x86_64/egg/apex/pyprof/prof\n",
            "copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/prof.py -> build/bdist.linux-x86_64/egg/apex/pyprof/prof\n",
            "copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/loss.py -> build/bdist.linux-x86_64/egg/apex/pyprof/prof\n",
            "copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/misc.py -> build/bdist.linux-x86_64/egg/apex/pyprof/prof\n",
            "creating build/bdist.linux-x86_64/egg/apex/reparameterization\n",
            "copying build/lib.linux-x86_64-3.6/apex/reparameterization/__init__.py -> build/bdist.linux-x86_64/egg/apex/reparameterization\n",
            "copying build/lib.linux-x86_64-3.6/apex/reparameterization/weight_norm.py -> build/bdist.linux-x86_64/egg/apex/reparameterization\n",
            "copying build/lib.linux-x86_64-3.6/apex/reparameterization/reparameterization.py -> build/bdist.linux-x86_64/egg/apex/reparameterization\n",
            "copying build/lib.linux-x86_64-3.6/apex_C.cpython-36m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/egg\n",
            "copying build/lib.linux-x86_64-3.6/amp_C.cpython-36m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/egg\n",
            "copying build/lib.linux-x86_64-3.6/syncbn.cpython-36m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/egg\n",
            "copying build/lib.linux-x86_64-3.6/fused_layer_norm_cuda.cpython-36m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/egg\n",
            "copying build/lib.linux-x86_64-3.6/mlp_cuda.cpython-36m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/egg\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/RNN/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/RNN/RNNBackend.py to RNNBackend.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/RNN/cells.py to cells.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/RNN/models.py to models.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/_initialize.py to _initialize.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/rnn_compat.py to rnn_compat.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/compat.py to compat.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/amp.py to amp.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/_process_optimizer.py to _process_optimizer.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/handle.py to handle.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/_amp_state.py to _amp_state.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/scaler.py to scaler.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/frontend.py to frontend.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/utils.py to utils.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/opt.py to opt.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/__version__.py to __version__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/wrap.py to wrap.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/lists/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/lists/tensor_overrides.py to tensor_overrides.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/lists/torch_overrides.py to torch_overrides.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/lists/functional_overrides.py to functional_overrides.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/groupbn/batch_norm.py to batch_norm.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/groupbn/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn/encdec_multihead_attn_func.py to encdec_multihead_attn_func.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn/fast_self_multihead_attn_func.py to fast_self_multihead_attn_func.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py to fast_encdec_multihead_attn_func.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn/self_multihead_attn.py to self_multihead_attn.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py to fast_self_multihead_attn_norm_add_func.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn/mask_softmax_dropout_func.py to mask_softmax_dropout_func.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py to fast_encdec_multihead_attn_norm_add_func.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn/self_multihead_attn_func.py to self_multihead_attn_func.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn/encdec_multihead_attn.py to encdec_multihead_attn.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/optimizers/distributed_fused_lamb.py to distributed_fused_lamb.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/optimizers/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/optimizers/distributed_fused_adam_v2.py to distributed_fused_adam_v2.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/optimizers/fused_adam.py to fused_adam.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/optimizers/distributed_fused_adam_v3.py to distributed_fused_adam_v3.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/optimizers/distributed_fused_adam.py to distributed_fused_adam.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/optimizers/fused_lamb.py to fused_lamb.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/optimizers/fp16_optimizer.py to fp16_optimizer.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/optimizers/fused_sgd.py to fused_sgd.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/sparsity/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/sparsity/asp.py to asp.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/sparsity/sparse_masklib.py to sparse_masklib.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/xentropy/softmax_xentropy.py to softmax_xentropy.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/xentropy/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/fp16_utils/fp16_optimizer.py to fp16_optimizer.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/fp16_utils/fp16util.py to fp16util.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/fp16_utils/loss_scaler.py to loss_scaler.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/fp16_utils/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/mlp/mlp.py to mlp.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/mlp/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/multi_tensor_apply/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/multi_tensor_apply/multi_tensor_apply.py to multi_tensor_apply.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/normalization/fused_layer_norm.py to fused_layer_norm.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/normalization/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/optimizers/fused_adagrad.py to fused_adagrad.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/optimizers/fused_lamb.py to fused_lamb.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/optimizers/fused_sgd.py to fused_sgd.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/optimizers/fused_novograd.py to fused_novograd.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/optimizers/fused_adam.py to fused_adam.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/optimizers/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/parallel/multiproc.py to multiproc.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/parallel/optimized_sync_batchnorm.py to optimized_sync_batchnorm.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/parallel/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/parallel/sync_batchnorm.py to sync_batchnorm.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/parallel/optimized_sync_batchnorm_kernel.py to optimized_sync_batchnorm_kernel.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/parallel/LARC.py to LARC.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/parallel/sync_batchnorm_kernel.py to sync_batchnorm_kernel.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/parallel/distributed.py to distributed.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/nvtx/nvmarker.py to nvmarker.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/nvtx/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/parse/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/parse/nvvp.py to nvvp.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/parse/db.py to db.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/parse/__main__.py to __main__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/parse/kernel.py to kernel.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/parse/parse.py to parse.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/prof/conv.py to conv.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/prof/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/prof/activation.py to activation.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/prof/blas.py to blas.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/prof/base.py to base.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/prof/__main__.py to __main__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/prof/normalization.py to normalization.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/prof/index_slice_join_mutate.py to index_slice_join_mutate.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/prof/usage.py to usage.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/prof/pooling.py to pooling.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/prof/convert.py to convert.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/prof/data.py to data.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/prof/linear.py to linear.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/prof/pointwise.py to pointwise.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/prof/embedding.py to embedding.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/prof/reduction.py to reduction.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/prof/optim.py to optim.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/prof/utility.py to utility.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/prof/recurrentCell.py to recurrentCell.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/prof/output.py to output.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/prof/softmax.py to softmax.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/prof/dropout.py to dropout.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/prof/randomSample.py to randomSample.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/prof/prof.py to prof.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/prof/loss.py to loss.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/prof/misc.py to misc.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/reparameterization/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/reparameterization/weight_norm.py to weight_norm.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/reparameterization/reparameterization.py to reparameterization.cpython-36.pyc\n",
            "creating stub loader for apex_C.cpython-36m-x86_64-linux-gnu.so\n",
            "creating stub loader for amp_C.cpython-36m-x86_64-linux-gnu.so\n",
            "creating stub loader for syncbn.cpython-36m-x86_64-linux-gnu.so\n",
            "creating stub loader for fused_layer_norm_cuda.cpython-36m-x86_64-linux-gnu.so\n",
            "creating stub loader for mlp_cuda.cpython-36m-x86_64-linux-gnu.so\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex_C.py to apex_C.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/amp_C.py to amp_C.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syncbn.py to syncbn.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/fused_layer_norm_cuda.py to fused_layer_norm_cuda.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/mlp_cuda.py to mlp_cuda.cpython-36.pyc\n",
            "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying apex.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying apex.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying apex.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying apex.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "writing build/bdist.linux-x86_64/egg/EGG-INFO/native_libs.txt\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "__pycache__.amp_C.cpython-36: module references __file__\n",
            "__pycache__.apex_C.cpython-36: module references __file__\n",
            "__pycache__.fused_layer_norm_cuda.cpython-36: module references __file__\n",
            "__pycache__.mlp_cuda.cpython-36: module references __file__\n",
            "__pycache__.syncbn.cpython-36: module references __file__\n",
            "apex.pyprof.nvtx.__pycache__.nvmarker.cpython-36: module references __file__\n",
            "apex.pyprof.nvtx.__pycache__.nvmarker.cpython-36: module references __path__\n",
            "creating 'dist/apex-0.1-py3.6-linux-x86_64.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
            "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
            "Processing apex-0.1-py3.6-linux-x86_64.egg\n",
            "creating /usr/local/lib/python3.6/dist-packages/apex-0.1-py3.6-linux-x86_64.egg\n",
            "Extracting apex-0.1-py3.6-linux-x86_64.egg to /usr/local/lib/python3.6/dist-packages\n",
            "Adding apex 0.1 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.6/dist-packages/apex-0.1-py3.6-linux-x86_64.egg\n",
            "Processing dependencies for apex==0.1\n",
            "Finished processing dependencies for apex==0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tbveiYn9pPHn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P7LcaZtNPCGf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e9a8137b-39e9-4285-a0e5-cefebf9443ab"
      },
      "source": [
        "train = pd.read_csv('/content/drive/My Drive/Data/New_200K_Jokes/train.csv')\n",
        "train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(160000, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lszsdfRf8atK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c18384a7-dea4-46b2-9d8a-a6ba3933dc4b"
      },
      "source": [
        "dev = pd.read_csv('/content/drive/My Drive/Data/New_200K_Jokes/dev.csv')\n",
        "dev.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(40000, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AyExqUAqPCGh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "04723d92-f6ef-4204-b1c4-84d88322eecd"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>humor</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Joe biden rules out 2020 bid: 'guys, i'm not r...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Watch: darvish gave hitter whiplash with slow ...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>What do you call a turtle without its shell? d...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5 reasons the 2016 election feels so personal</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Pasco police shot mexican migrant from behind,...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  humor\n",
              "0  Joe biden rules out 2020 bid: 'guys, i'm not r...  False\n",
              "1  Watch: darvish gave hitter whiplash with slow ...  False\n",
              "2  What do you call a turtle without its shell? d...   True\n",
              "3      5 reasons the 2016 election feels so personal  False\n",
              "4  Pasco police shot mexican migrant from behind,...  False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZGFVn8YylXb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train['number_of_words'] = train.text.apply(lambda x: len(x.split()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qMO_w5Jf6Y58",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "83074e24-6e3a-4259-a136-663d1a7974db"
      },
      "source": [
        "train.dtypes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "text               object\n",
              "humor                bool\n",
              "number_of_words     int64\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zMCBM9Fm8dzE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "8ee00e3d-b0a9-4d05-f1ac-7eaad6478695"
      },
      "source": [
        "dev.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>humor</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What kind of cat should you take into the  des...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Remember when people used to have to be in sha...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Pizza is always good. - everyone we'll see abo...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What's 6 inches long hard, bent, and in my pan...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Black teen's response to violence in his commu...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  humor\n",
              "0  What kind of cat should you take into the  des...   True\n",
              "1  Remember when people used to have to be in sha...   True\n",
              "2  Pizza is always good. - everyone we'll see abo...   True\n",
              "3  What's 6 inches long hard, bent, and in my pan...   True\n",
              "4  Black teen's response to violence in his commu...  False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MyZ0XO0ryroQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dev['number_of_words'] = dev.text.apply(lambda x: len(x.split()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jE6eoQxJ6fm3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "b6678685-0deb-4363-e4fa-2c6c8875438d"
      },
      "source": [
        "dev.dtypes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "text               object\n",
              "humor                bool\n",
              "number_of_words     int64\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EdoiQA1Hy31B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Visual(df):\n",
        "    max_len = max(df.number_of_words)\n",
        "    print('Length of Data = {}'.format(len(df)))\n",
        "    print('No. of item with output 0 are = {}'.format(len(df[df['humor']==True])))\n",
        "    print('No. of item with output 1 are = {}'.format(len(df[df['humor']==False]))) \n",
        "    print('Maximum length of a text in all texts = {}'.format(max_len)) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rwni2_CDy5By",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "52fe6ec8-10d5-4aff-ec6d-063928201058"
      },
      "source": [
        "Visual(train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of Data = 160000\n",
            "No. of item with output 0 are = 79918\n",
            "No. of item with output 1 are = 80082\n",
            "Maximum length of a text in all texts = 18\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O38WYyG6zgPp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "62c756ca-6955-426f-8faa-0387cffc6908"
      },
      "source": [
        "Visual(dev)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of Data = 40000\n",
            "No. of item with output 0 are = 20082\n",
            "No. of item with output 1 are = 19918\n",
            "Maximum length of a text in all texts = 18\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SGGE4uE6PCGy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_sentence_embeddings_length(text_list, tokenizer):\n",
        "    tokenized_texts = list(map(lambda t: tokenizer.tokenize(t), text_list))\n",
        "    tokenized_texts_len = list(map(lambda t: len(t), tokenized_texts))\n",
        "    fig, ax = plt.subplots(figsize=(8, 5));\n",
        "    ax.hist(tokenized_texts_len, bins=40);\n",
        "    ax.set_xlabel(\"Length of Comment Embeddings\");\n",
        "    ax.set_ylabel(\"Number of Comments\");\n",
        "    return"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdQE9k9yPCG4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188,
          "referenced_widgets": [
            "886cd988bcf94ebc92e7438d031f515e",
            "c58276e8e5f64dbc9093104a986d30b8",
            "a19401c45e314fd09a86823a5a253051",
            "585611b34ae244a883975ba017223451",
            "a18bc8bb7c2f4314940c15a2dd995630",
            "077deba028e64d93a4e74b36b5300b7b",
            "ef9681bf3b234ed388495bdb7875e079",
            "991da577c8d34a688e2837776d7d8eee"
          ]
        },
        "outputId": "12e717d3-75c5-43ba-df2a-29cc6d50b5ef"
      },
      "source": [
        "tokenizer = XLNetTokenizer.from_pretrained('xlnet-base-cased', do_lower_case=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:filelock:Lock 140559625834000 acquired on /root/.cache/torch/transformers/dad589d582573df0293448af5109cb6981ca77239ed314e15ca63b7b8a318ddd.8b10bd978b5d01c21303cc761fc9ecd464419b3bf921864a355ba807cfbfafa8.lock\n",
            "INFO:transformers.file_utils:https://s3.amazonaws.com/models.huggingface.co/bert/xlnet-base-cased-spiece.model not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmpuclze1rq\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "886cd988bcf94ebc92e7438d031f515e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=798011.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:transformers.file_utils:storing https://s3.amazonaws.com/models.huggingface.co/bert/xlnet-base-cased-spiece.model in cache at /root/.cache/torch/transformers/dad589d582573df0293448af5109cb6981ca77239ed314e15ca63b7b8a318ddd.8b10bd978b5d01c21303cc761fc9ecd464419b3bf921864a355ba807cfbfafa8\n",
            "INFO:transformers.file_utils:creating metadata file for /root/.cache/torch/transformers/dad589d582573df0293448af5109cb6981ca77239ed314e15ca63b7b8a318ddd.8b10bd978b5d01c21303cc761fc9ecd464419b3bf921864a355ba807cfbfafa8\n",
            "INFO:filelock:Lock 140559625834000 released on /root/.cache/torch/transformers/dad589d582573df0293448af5109cb6981ca77239ed314e15ca63b7b8a318ddd.8b10bd978b5d01c21303cc761fc9ecd464419b3bf921864a355ba807cfbfafa8.lock\n",
            "INFO:transformers.tokenization_utils_base:loading file https://s3.amazonaws.com/models.huggingface.co/bert/xlnet-base-cased-spiece.model from cache at /root/.cache/torch/transformers/dad589d582573df0293448af5109cb6981ca77239ed314e15ca63b7b8a318ddd.8b10bd978b5d01c21303cc761fc9ecd464419b3bf921864a355ba807cfbfafa8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phJqr8QBPCG8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_text_list = train[\"text\"].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-oGicDF8jhw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dev_text_list = dev[\"text\"].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fri247sJPCG-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "outputId": "be30c2aa-853e-4389-d5b0-dcf08b09707a"
      },
      "source": [
        "plot_sentence_embeddings_length(train_text_list, tokenizer)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RRCnqd6g65Zg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "outputId": "427ce548-60f1-4882-a076-66713dfc02f0"
      },
      "source": [
        "plot_sentence_embeddings_length(dev_text_list, tokenizer)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9o-aKUwLPCHF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenize_inputs(text_list, tokenizer, num_embeddings):\n",
        "    \"\"\"\n",
        "    Tokenizes the input text input into ids. Appends the appropriate special\n",
        "    characters to the end of the text to denote end of sentence. Truncate or pad\n",
        "    the appropriate sequence length.\n",
        "    \"\"\"\n",
        "    # tokenize the text, then truncate sequence to the desired length minus 2 for\n",
        "    # the 2 special characters\n",
        "    tokenized_texts = list(map(lambda t: tokenizer.tokenize(t)[:num_embeddings-2], text_list))\n",
        "    # convert tokenized text into numeric ids for the appropriate LM\n",
        "    input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
        "    # append special token \"<s>\" and </s> to end of sentence\n",
        "    input_ids = [tokenizer.build_inputs_with_special_tokens(x) for x in input_ids]\n",
        "    # pad sequences\n",
        "    input_ids = pad_sequences(input_ids, maxlen=num_embeddings, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "    input_ids = np.array(input_ids)\n",
        "    return input_ids\n",
        "\n",
        "def create_attn_masks(input_ids):\n",
        "    \"\"\"\n",
        "    Create attention masks to tell model whether attention should be applied to\n",
        "    the input id tokens. Do not want to perform attention on padding tokens.\n",
        "    \"\"\"\n",
        "    # Create attention masks\n",
        "    attention_masks = []\n",
        "\n",
        "    # Create a mask of 1s for each token followed by 0s for padding\n",
        "    for seq in input_ids:\n",
        "        seq_mask = [float(i>0) for i in seq]\n",
        "        attention_masks.append(seq_mask)\n",
        "    attention_masks = np.array(attention_masks)\n",
        "    return attention_masks"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UORljp7APCHK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "d79079ca-ce2b-44cd-a17e-cd820702f1b3"
      },
      "source": [
        "# create input id tokens\n",
        "train_input_ids = tokenize_inputs(train_text_list, tokenizer, num_embeddings=50)\n",
        "print(train_input_ids.shape)\n",
        "train_input_ids"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(160000, 50)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   17,  2595,    93, ...,     0,     0,     0],\n",
              "       [ 1628,    60,    17, ...,     0,     0,     0],\n",
              "       [  113,   112,    44, ...,     0,     0,     0],\n",
              "       ...,\n",
              "       [  108,   886,   855, ...,     0,     0,     0],\n",
              "       [   17,   150,    26, ...,     0,     0,     0],\n",
              "       [ 2302, 10738,    61, ...,     0,     0,     0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8M-CiGpcPCHN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f7fb71a3-b57d-4705-e8f9-243bec69e329"
      },
      "source": [
        "# create attention masks\n",
        "train_attention_masks = create_attn_masks(train_input_ids)\n",
        "train_attention_masks.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(160000, 50)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_06NLtJa8qn8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "771e4fe5-14a7-4ef2-b509-bb8d8875d18d"
      },
      "source": [
        "# create input id tokens\n",
        "dev_input_ids = tokenize_inputs(dev_text_list, tokenizer, num_embeddings=50)\n",
        "print(dev_input_ids.shape)\n",
        "dev_input_ids"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(40000, 50)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  113,   713,    20, ...,     0,     0,     0],\n",
              "       [ 1633,    90,   104, ...,     0,     0,     0],\n",
              "       [12879,    27,   426, ...,     0,     0,     0],\n",
              "       ...,\n",
              "       [  160,   142,  8959, ...,     0,     0,     0],\n",
              "       [   17,    98,   369, ...,     0,     0,     0],\n",
              "       [   48,    17,  1121, ...,     0,     0,     0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kkhrlg2U8qcQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "35451c73-cb13-403c-cfb5-d27575d6c25b"
      },
      "source": [
        "# create attention masks\n",
        "dev_attention_masks = create_attn_masks(dev_input_ids)\n",
        "dev_attention_masks.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(40000, 50)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BlgaFcTnPCHX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "154b7a42-e561-4bbc-829d-6d11351135f1"
      },
      "source": [
        "# add input ids and attention masks to the dataframe\n",
        "train[\"features\"] = train_input_ids.tolist()\n",
        "train[\"masks\"] = train_attention_masks.tolist()\n",
        "train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>humor</th>\n",
              "      <th>number_of_words</th>\n",
              "      <th>features</th>\n",
              "      <th>masks</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Joe biden rules out 2020 bid: 'guys, i'm not r...</td>\n",
              "      <td>False</td>\n",
              "      <td>10</td>\n",
              "      <td>[17, 2595, 93, 2340, 254, 1414, 78, 15765, 234...</td>\n",
              "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Watch: darvish gave hitter whiplash with slow ...</td>\n",
              "      <td>False</td>\n",
              "      <td>8</td>\n",
              "      <td>[1628, 60, 17, 5072, 25489, 675, 17, 11753, 14...</td>\n",
              "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>What do you call a turtle without its shell? d...</td>\n",
              "      <td>True</td>\n",
              "      <td>10</td>\n",
              "      <td>[113, 112, 44, 547, 24, 15700, 286, 81, 6197, ...</td>\n",
              "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5 reasons the 2016 election feels so personal</td>\n",
              "      <td>False</td>\n",
              "      <td>8</td>\n",
              "      <td>[306, 2113, 18, 2884, 821, 4760, 102, 739, 4, ...</td>\n",
              "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Pasco police shot mexican migrant from behind,...</td>\n",
              "      <td>False</td>\n",
              "      <td>10</td>\n",
              "      <td>[943, 19301, 365, 938, 110, 6269, 2392, 21726,...</td>\n",
              "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  ...                                              masks\n",
              "0  Joe biden rules out 2020 bid: 'guys, i'm not r...  ...  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...\n",
              "1  Watch: darvish gave hitter whiplash with slow ...  ...  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...\n",
              "2  What do you call a turtle without its shell? d...  ...  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...\n",
              "3      5 reasons the 2016 election feels so personal  ...  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...\n",
              "4  Pasco police shot mexican migrant from behind,...  ...  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lvSsNool89Av",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "0ab607db-519b-476c-aa75-82a2d44f6bf4"
      },
      "source": [
        "# add input ids and attention masks to the dataframe\n",
        "dev[\"features\"] = dev_input_ids.tolist()\n",
        "dev[\"masks\"] = dev_attention_masks.tolist()\n",
        "dev.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>humor</th>\n",
              "      <th>number_of_words</th>\n",
              "      <th>features</th>\n",
              "      <th>masks</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What kind of cat should you take into the  des...</td>\n",
              "      <td>True</td>\n",
              "      <td>16</td>\n",
              "      <td>[113, 713, 20, 4777, 170, 44, 182, 91, 18, 567...</td>\n",
              "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Remember when people used to have to be in sha...</td>\n",
              "      <td>True</td>\n",
              "      <td>14</td>\n",
              "      <td>[1633, 90, 104, 179, 22, 47, 22, 39, 25, 2787,...</td>\n",
              "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Pizza is always good. - everyone we'll see abo...</td>\n",
              "      <td>True</td>\n",
              "      <td>13</td>\n",
              "      <td>[12879, 27, 426, 195, 9, 17, 13, 1251, 80, 26,...</td>\n",
              "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What's 6 inches long hard, bent, and in my pan...</td>\n",
              "      <td>True</td>\n",
              "      <td>13</td>\n",
              "      <td>[113, 26, 23, 284, 3763, 206, 500, 19, 9015, 1...</td>\n",
              "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Black teen's response to violence in his commu...</td>\n",
              "      <td>False</td>\n",
              "      <td>11</td>\n",
              "      <td>[710, 8017, 26, 23, 1196, 22, 1350, 25, 45, 53...</td>\n",
              "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  ...                                              masks\n",
              "0  What kind of cat should you take into the  des...  ...  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...\n",
              "1  Remember when people used to have to be in sha...  ...  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...\n",
              "2  Pizza is always good. - everyone we'll see abo...  ...  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...\n",
              "3  What's 6 inches long hard, bent, and in my pan...  ...  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...\n",
              "4  Black teen's response to violence in his commu...  ...  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQr9zFBCPCHc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "b3e05239bc2d456bbbb1eecdcf42dda9",
            "421ac4013f6343d5a6ae74e36011cc77",
            "28f39bead17e40f9abfc05f820028ea2",
            "7b5c5ad4baea4087b9f851552e3f22f7",
            "b304e30b0e58451cb7cf5131f9874e28",
            "a2d284d115b74ee08ba56b33c6f2d841",
            "d8677dabede44c18a8fcbec6900039ce",
            "ecc0c1b3c0d846f2aa7e7e22021cc8f8",
            "2b910e363acb4f739b48daead2eea64f",
            "18d090a3fa7448bb83670b60d54e8bfa",
            "034d3dc557544f03b8e30a6d6ab755f0",
            "20b7c4b41a8b42eaa8f7a06dbcc7cdce",
            "2ddf47d84ac948d5a86793b99ddf75d8",
            "7d85cc6324ce47eeaa73012f279c97ff",
            "d1200bf2bbbf4fdb9d97098e1147ebfb",
            "c79979acd68547d5b78f5d0ff4fd3e69"
          ]
        },
        "outputId": "7b5ad98b-4473-48c7-b724-98ef1f4116a7"
      },
      "source": [
        "#config = XLNetConfig()\n",
        "        \n",
        "class XLNetForMultiLabelSequenceClassification(torch.nn.Module):\n",
        "  \n",
        "    def __init__(self, num_labels=1):\n",
        "        super(XLNetForMultiLabelSequenceClassification, self).__init__()\n",
        "        self.num_labels = num_labels\n",
        "        self.xlnet = XLNetModel.from_pretrained('xlnet-base-cased')\n",
        "        self.classifier = torch.nn.Linear(768, num_labels)\n",
        "\n",
        "        torch.nn.init.xavier_normal_(self.classifier.weight)\n",
        "\n",
        "    def forward(self, input_ids, token_type_ids=None, attention_mask=None, labels=None):\n",
        "        # last hidden layer\n",
        "        last_hidden_state = self.xlnet(input_ids=input_ids,\\\n",
        "                                    attention_mask=attention_mask,\\\n",
        "                                    token_type_ids=token_type_ids)\n",
        "        # pool the outputs into a mean vector\n",
        "        mean_last_hidden_state = self.pool_hidden_state(last_hidden_state)\n",
        "        logits = self.classifier(mean_last_hidden_state)\n",
        "            \n",
        "        if labels is not None:\n",
        "            loss_fct = BCEWithLogitsLoss()\n",
        "            loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1, self.num_labels))\n",
        "            return loss\n",
        "        else:\n",
        "            return logits\n",
        "\n",
        "    def freeze_xlnet_decoder(self):\n",
        "        \"\"\"\n",
        "        Freeze XLNet weight parameters. They will not be updated during training.\n",
        "        \"\"\"\n",
        "        for param in self.xlnet.parameters():\n",
        "            param.requires_grad = False\n",
        "    \n",
        "    def unfreeze_xlnet_decoder(self):\n",
        "        \"\"\"\n",
        "        Unfreeze XLNet weight parameters. They will be updated during training.\n",
        "        \"\"\"\n",
        "        for param in self.xlnet.parameters():\n",
        "            param.requires_grad = True\n",
        "\n",
        "    def pool_hidden_state(self, last_hidden_state):\n",
        "        \"\"\"\n",
        "        Pool the output vectors into a single mean vector \n",
        "        \"\"\"\n",
        "        last_hidden_state = last_hidden_state[0]\n",
        "        mean_last_hidden_state = torch.mean(last_hidden_state, 1)\n",
        "        return mean_last_hidden_state\n",
        "\n",
        "model = XLNetForMultiLabelSequenceClassification(num_labels=1)\n",
        "# model = XLNetForSequenceClassification.from_pretrained('xlnet-base-cased')\n",
        "model.cuda()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:filelock:Lock 140556899865152 acquired on /root/.cache/torch/transformers/c9cc6e53904f7f3679a31ec4af244f4419e25ebc8e71ebf8c558a31cbcf07fc8.69e5e35e0b798cab5e473f253752f8bf4d280ee37682281a23eed80f6e2d09c6.lock\n",
            "INFO:transformers.file_utils:https://s3.amazonaws.com/models.huggingface.co/bert/xlnet-base-cased-config.json not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmp8vaumgx9\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b3e05239bc2d456bbbb1eecdcf42dda9",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=760.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:transformers.file_utils:storing https://s3.amazonaws.com/models.huggingface.co/bert/xlnet-base-cased-config.json in cache at /root/.cache/torch/transformers/c9cc6e53904f7f3679a31ec4af244f4419e25ebc8e71ebf8c558a31cbcf07fc8.69e5e35e0b798cab5e473f253752f8bf4d280ee37682281a23eed80f6e2d09c6\n",
            "INFO:transformers.file_utils:creating metadata file for /root/.cache/torch/transformers/c9cc6e53904f7f3679a31ec4af244f4419e25ebc8e71ebf8c558a31cbcf07fc8.69e5e35e0b798cab5e473f253752f8bf4d280ee37682281a23eed80f6e2d09c6\n",
            "INFO:filelock:Lock 140556899865152 released on /root/.cache/torch/transformers/c9cc6e53904f7f3679a31ec4af244f4419e25ebc8e71ebf8c558a31cbcf07fc8.69e5e35e0b798cab5e473f253752f8bf4d280ee37682281a23eed80f6e2d09c6.lock\n",
            "INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/xlnet-base-cased-config.json from cache at /root/.cache/torch/transformers/c9cc6e53904f7f3679a31ec4af244f4419e25ebc8e71ebf8c558a31cbcf07fc8.69e5e35e0b798cab5e473f253752f8bf4d280ee37682281a23eed80f6e2d09c6\n",
            "INFO:transformers.configuration_utils:Model config XLNetConfig {\n",
            "  \"architectures\": [\n",
            "    \"XLNetLMHeadModel\"\n",
            "  ],\n",
            "  \"attn_type\": \"bi\",\n",
            "  \"bi_data\": false,\n",
            "  \"bos_token_id\": 1,\n",
            "  \"clamp_len\": -1,\n",
            "  \"d_head\": 64,\n",
            "  \"d_inner\": 3072,\n",
            "  \"d_model\": 768,\n",
            "  \"dropout\": 0.1,\n",
            "  \"end_n_top\": 5,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"ff_activation\": \"gelu\",\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"mem_len\": null,\n",
            "  \"model_type\": \"xlnet\",\n",
            "  \"n_head\": 12,\n",
            "  \"n_layer\": 12,\n",
            "  \"pad_token_id\": 5,\n",
            "  \"reuse_len\": null,\n",
            "  \"same_length\": false,\n",
            "  \"start_n_top\": 5,\n",
            "  \"summary_activation\": \"tanh\",\n",
            "  \"summary_last_dropout\": 0.1,\n",
            "  \"summary_type\": \"last\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 250\n",
            "    }\n",
            "  },\n",
            "  \"untie_r\": true,\n",
            "  \"vocab_size\": 32000\n",
            "}\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:filelock:Lock 140556900196816 acquired on /root/.cache/torch/transformers/33d6135fea0154c088449506a4c5f9553cb59b6fd040138417a7033af64bb8f9.7eac4fe898a021204e63c88c00ea68c60443c57f94b4bc3c02adbde6465745ac.lock\n",
            "INFO:transformers.file_utils:https://cdn.huggingface.co/xlnet-base-cased-pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmp248g7tkp\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2b910e363acb4f739b48daead2eea64f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=467042463.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:transformers.file_utils:storing https://cdn.huggingface.co/xlnet-base-cased-pytorch_model.bin in cache at /root/.cache/torch/transformers/33d6135fea0154c088449506a4c5f9553cb59b6fd040138417a7033af64bb8f9.7eac4fe898a021204e63c88c00ea68c60443c57f94b4bc3c02adbde6465745ac\n",
            "INFO:transformers.file_utils:creating metadata file for /root/.cache/torch/transformers/33d6135fea0154c088449506a4c5f9553cb59b6fd040138417a7033af64bb8f9.7eac4fe898a021204e63c88c00ea68c60443c57f94b4bc3c02adbde6465745ac\n",
            "INFO:filelock:Lock 140556900196816 released on /root/.cache/torch/transformers/33d6135fea0154c088449506a4c5f9553cb59b6fd040138417a7033af64bb8f9.7eac4fe898a021204e63c88c00ea68c60443c57f94b4bc3c02adbde6465745ac.lock\n",
            "INFO:transformers.modeling_utils:loading weights file https://cdn.huggingface.co/xlnet-base-cased-pytorch_model.bin from cache at /root/.cache/torch/transformers/33d6135fea0154c088449506a4c5f9553cb59b6fd040138417a7033af64bb8f9.7eac4fe898a021204e63c88c00ea68c60443c57f94b4bc3c02adbde6465745ac\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:transformers.modeling_utils:All model checkpoint weights were used when initializing XLNetModel.\n",
            "\n",
            "INFO:transformers.modeling_utils:All the weights of XLNetModel were initialized from the model checkpoint at xlnet-base-cased.\n",
            "If your task is similar to the task the model of the ckeckpoint was trained on, you can already use XLNetModel for predictions without further training.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XLNetForMultiLabelSequenceClassification(\n",
              "  (xlnet): XLNetModel(\n",
              "    (word_embedding): Embedding(32000, 768)\n",
              "    (layer): ModuleList(\n",
              "      (0): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (1): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (2): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (3): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (4): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (5): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (6): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (7): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (8): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (9): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (10): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (11): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (classifier): Linear(in_features=768, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gde2ZD2hPCHe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def trainnig(device, model, num_epochs, optimizer, scheduler, train_dataloader, valid_dataloader, model_save_path, start_epoch=0, lowest_eval_loss=None, train_loss_set=[], valid_loss_set = []):\n",
        "    \"\"\"\n",
        "    Train the model and save the model with the lowest validation loss\n",
        "    \"\"\"\n",
        "    logger.info(\"***** Running training *****\")\n",
        "    logger.info(\"  Total train batch size = %d\", len(train_dataloader))\n",
        "    logger.info(\"  Total validation batch size  = %d\", len(valid_dataloader))\n",
        "    logger.info(\"  Num Epochs = %d\", num_epochs)\n",
        "    \n",
        "    if True:\n",
        "        try:\n",
        "            from apex import amp\n",
        "        except ImportError:\n",
        "            raise ImportError(\"Please install apex from https://www.github.com/nvidia/apex to use fp16 training.\")\n",
        "        model, optimizer = amp.initialize(model, optimizer, opt_level='O1')\n",
        "    model = torch.nn.DataParallel(model)\n",
        "   \n",
        "    model.to(device)\n",
        " \n",
        "    # trange is a tqdm wrapper around the normal python range\n",
        "    for i in trange(num_epochs, desc=\"Epoch\"):\n",
        "        # if continue training from saved model\n",
        "        actual_epoch = start_epoch + i + 1\n",
        "        print(\"\\n\\n\\n***** Epoch No.: {} *****\\n\".format(actual_epoch))\n",
        "        # Training\n",
        "        # Set our model to training mode (as opposed to evaluation mode)\n",
        "        model.train()\n",
        " \n",
        "        # Tracking variables\n",
        "        tr_loss = 0\n",
        "        num_train_samples = 0\n",
        " \n",
        "        # Train the data for one epoch\n",
        "        batch_no = 0\n",
        "        for step, batch in enumerate(train_dataloader):\n",
        "            # Add batch to GPU\n",
        "            batch = tuple(t.to(device) for t in batch)\n",
        "            batch_no += 1\n",
        "            \n",
        "            # Unpack the inputs from our dataloader\n",
        "            b_input_ids, b_input_mask, b_labels = batch\n",
        "            # Clear out the gradients (by default they accumulate)\n",
        "            optimizer.zero_grad()\n",
        "            # Forward pass\n",
        "            loss = model(b_input_ids, attention_mask=b_input_mask, labels=b_labels)\n",
        "            # store train loss\n",
        "            tr_loss += loss.item()\n",
        "            num_train_samples += b_labels.size(0)\n",
        "            # Backward pass\n",
        "            loss.backward()\n",
        "            # Update parameters and take a step using the computed gradient\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        " \n",
        "        # Update tracking variables\n",
        "        epoch_train_loss = tr_loss/num_train_samples\n",
        "        train_loss_set.append(epoch_train_loss)\n",
        " \n",
        "        print(\"\\nTrain loss: {}\".format(epoch_train_loss))\n",
        " \n",
        "        # Validation\n",
        " \n",
        "        # Put model in evaluation mode to evaluate loss on the validation set\n",
        "        model.eval()\n",
        " \n",
        "        # Tracking variables \n",
        "        eval_loss = 0\n",
        "        num_eval_samples = 0\n",
        " \n",
        "        # Evaluate data for one epoch\n",
        "        for batch in valid_dataloader:\n",
        "            # Add batch to GPU\n",
        "            batch = tuple(t.to(device) for t in batch)\n",
        "            # Unpack the inputs from our dataloader\n",
        "            b_input_ids, b_input_mask, b_labels = batch\n",
        "            # Telling the model not to compute or store gradients,\n",
        "            # saving memory and speeding up validation\n",
        "            with torch.no_grad():\n",
        "            # Forward pass, calculate validation loss\n",
        "                loss = model(b_input_ids, attention_mask=b_input_mask, labels=b_labels)\n",
        "                # store valid loss\n",
        "                eval_loss += loss.item()\n",
        "                num_eval_samples += b_labels.size(0)\n",
        " \n",
        "        epoch_eval_loss = eval_loss/num_eval_samples\n",
        "        valid_loss_set.append(epoch_eval_loss)\n",
        " \n",
        "        print(\"\\nValid loss: {}\".format(epoch_eval_loss))\n",
        " \n",
        "        if lowest_eval_loss == None:\n",
        "            lowest_eval_loss = epoch_eval_loss\n",
        "            # save model\n",
        "            save_model(model, model_save_path, actual_epoch, lowest_eval_loss, train_loss_set, valid_loss_set)\n",
        "        else:\n",
        "            if epoch_eval_loss < lowest_eval_loss:\n",
        "                lowest_eval_loss = epoch_eval_loss\n",
        "                # save model\n",
        "                save_model(model, model_save_path, actual_epoch, lowest_eval_loss, train_loss_set, valid_loss_set)\n",
        "        print(\"\\n\")\n",
        " \n",
        "    return model, train_loss_set, valid_loss_set\n",
        " \n",
        " \n",
        "def save_model(model, save_path, epochs, lowest_eval_loss, train_loss_hist, valid_loss_hist):\n",
        "    \"\"\"\n",
        "    Save the model to the path directory provided\n",
        "    \"\"\"\n",
        "    model_to_save = model.module if hasattr(model, 'module') else model\n",
        "    checkpoint = {'epochs': epochs, \\\n",
        "                'lowest_eval_loss': lowest_eval_loss,\\\n",
        "                'state_dict': model_to_save.state_dict(),\\\n",
        "                'train_loss_hist': train_loss_hist,\\\n",
        "                'valid_loss_hist': valid_loss_hist\n",
        "                }\n",
        "    torch.save(checkpoint, save_path)\n",
        "    print(\"\\nSaving model at epoch {} with validation loss of {}\".format(epochs,lowest_eval_loss))\n",
        "    return\n",
        "  \n",
        "def load_model(save_path):\n",
        "    \"\"\"\n",
        "    Load the model from the path directory provided\n",
        "    \"\"\"\n",
        "    checkpoint = torch.load(save_path)\n",
        "    model_state_dict = checkpoint['state_dict']\n",
        "#     model = XLNetForMultiLabelSequenceClassification(num_labels=model_state_dict[\"classifier.weight\"].size()[0])\n",
        "    model.load_state_dict(model_state_dict)\n",
        " \n",
        "    epochs = checkpoint[\"epochs\"]\n",
        "    lowest_eval_loss = checkpoint[\"lowest_eval_loss\"]\n",
        "    train_loss_hist = checkpoint[\"train_loss_hist\"]\n",
        "    valid_loss_hist = checkpoint[\"valid_loss_hist\"]\n",
        " \n",
        "    return model, epochs, lowest_eval_loss, train_loss_hist, valid_loss_hist"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJv7TTudPCHh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hcmOo3_bVg3e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = train[\"features\"].values.tolist()\n",
        "X_valid = dev[\"features\"].values.tolist()\n",
        "\n",
        "train_masks = train[\"masks\"].values.tolist()\n",
        "valid_masks = dev[\"masks\"].values.tolist()\n",
        "\n",
        "label_cols = [\"humor\"]\n",
        "Y_train = train[label_cols].values.tolist()\n",
        "Y_valid = dev[label_cols].values.tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c13GYiVvPCHm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "outputId": "36a0ec3f-d056-4c8e-9284-9c2af09e2d0d"
      },
      "source": [
        "print('One Example of X_train:\\n{}\\n'.format(X_train[0]))\n",
        "print('One Example of X_valid:\\n{}\\n'.format(X_valid[0]))\n",
        "\n",
        "print('One Example of train_masks:\\n{}\\n'.format(train_masks[0]))\n",
        "print('One Example of valid_masks:\\n{}\\n'.format(valid_masks[0]))\n",
        "\n",
        "print('One Example of Y_train:\\n{}\\n'.format(Y_train[0]))\n",
        "print('One Example of Y_valid:\\n{}\\n'.format(Y_valid[0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "One Example of X_train:\n",
            "[17, 2595, 93, 2340, 254, 1414, 78, 15765, 2340, 60, 17, 26, 3017, 117, 23, 19, 17, 150, 26, 98, 50, 926, 26, 4, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "One Example of X_valid:\n",
            "[113, 713, 20, 4777, 170, 44, 182, 91, 18, 5675, 17, 82, 24, 89, 1443, 8538, 982, 17, 136, 4, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "One Example of train_masks:\n",
            "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "\n",
            "One Example of valid_masks:\n",
            "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "\n",
            "One Example of Y_train:\n",
            "[False]\n",
            "\n",
            "One Example of Y_valid:\n",
            "[True]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pw1J5258PCHp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.set_default_tensor_type('torch.cuda.FloatTensor')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehp4CuhCWOGN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert all of our input ids and attention masks into \n",
        "# torch tensors, the required datatype for our model\n",
        "\n",
        "X_train = torch.tensor(X_train)\n",
        "X_valid = torch.tensor(X_valid)\n",
        "\n",
        "Y_train = torch.tensor(Y_train, dtype=torch.float32)\n",
        "Y_valid = torch.tensor(Y_valid, dtype=torch.float32)\n",
        "\n",
        "train_masks = torch.tensor(train_masks, dtype=torch.long)\n",
        "valid_masks = torch.tensor(valid_masks, dtype=torch.long)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4h8q2UjXCrP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Select a batch size for training\n",
        "batch_size = 32\n",
        "\n",
        "# Create an iterator of our data with torch DataLoader. This helps save on \n",
        "# memory during training because, unlike a for loop, \n",
        "# with an iterator the entire dataset does not need to be loaded into memory\n",
        "\n",
        "train_data = TensorDataset(X_train, train_masks, Y_train)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "validation_data = TensorDataset(X_valid, valid_masks, Y_valid)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0XwG_mcCqgGF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_epochs = 3\n",
        "num_total_steps = len(train_dataloader)*num_epochs\n",
        "optimizer = AdamW(model.parameters(), lr=1e-5, weight_decay=0.01, correct_bias=False)\n",
        "scheduler = WarmupLinearSchedule(optimizer, warmup_steps=0, t_total=num_total_steps)  # PyTorch scheduler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xXYOXmXXQcJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "6de4d8aa-d68a-448c-c2e1-bf6ca2b510f4"
      },
      "source": [
        "cwd = os.getcwd()\n",
        "model_save_path = output_model_file = os.path.join(cwd, \"/content/drive/My Drive/Data/New_200K_Jokes/xlnet_toxic.bin\")\n",
        "if os.path.exists(model_save_path):\n",
        "    print('Yes file Exists!')\n",
        "    os.remove(model_save_path)\n",
        "    print('Now, xlnet_toxic.bin File is removed!!')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Yes file Exists!\n",
            "Now, xlnet_toxic.bin File is removed!!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kjkbWolpRCFJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "446abfb3-329d-4df7-f5f5-2b7c1eca4ee6"
      },
      "source": [
        "printm()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Gen RAM Free: 10.1 GB  |     Proc size: 4.9 GB\n",
            "GPU RAM Free: 16280MB | Used: 0MB | Util   0% | Total     16280MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKcTftWz0AzP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a507140b-b058-4fa9-8f22-18f07582220c"
      },
      "source": [
        "torch.cuda.empty_cache()\n",
        "model, train_loss_set, valid_loss_set = trainnig(device = device, model=model, num_epochs=num_epochs, optimizer=optimizer,scheduler=scheduler, train_dataloader=train_dataloader, valid_dataloader=validation_dataloader, model_save_path=model_save_path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:__main__:***** Running training *****\n",
            "INFO:__main__:  Total train batch size = 5000\n",
            "INFO:__main__:  Total validation batch size  = 1250\n",
            "INFO:__main__:  Num Epochs = 3\n",
            "Epoch:   0%|          | 0/3 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.\n",
            "\n",
            "Defaults for this optimization level are:\n",
            "enabled                : True\n",
            "opt_level              : O1\n",
            "cast_model_type        : None\n",
            "patch_torch_functions  : True\n",
            "keep_batchnorm_fp32    : None\n",
            "master_weights         : None\n",
            "loss_scale             : dynamic\n",
            "Processing user overrides (additional kwargs that are not None)...\n",
            "After processing overrides, optimization options are:\n",
            "enabled                : True\n",
            "opt_level              : O1\n",
            "cast_model_type        : None\n",
            "patch_torch_functions  : True\n",
            "keep_batchnorm_fp32    : None\n",
            "master_weights         : None\n",
            "loss_scale             : dynamic\n",
            "Warning:  multi_tensor_applier fused unscale kernel is unavailable, possibly because apex was installed without --cuda_ext --cpp_ext. Using Python fallback.  Original ImportError was: ModuleNotFoundError(\"No module named 'amp_C'\",)\n",
            "\n",
            "\n",
            "\n",
            "***** Epoch No.: 1 *****\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
            "\tadd_(Number alpha, Tensor other)\n",
            "Consider using one of the following signatures instead:\n",
            "\tadd_(Tensor other, *, Number alpha)\n",
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:114: UserWarning: Seems like `optimizer.step()` has been overridden after learning rate scheduler initialization. Please, make sure to call `optimizer.step()` before `lr_scheduler.step()`. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Train loss: 0.0021679473160605995\n",
            "\n",
            "Valid loss: 0.0016755193166576646\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  33%|███▎      | 1/3 [19:36<39:12, 1176.30s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Saving model at epoch 1 with validation loss of 0.0016755193166576646\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "***** Epoch No.: 2 *****\n",
            "\n",
            "\n",
            "Train loss: 0.0012292418639344759\n",
            "\n",
            "Valid loss: 0.0013109843694721348\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  67%|██████▋   | 2/3 [39:10<19:35, 1175.75s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Saving model at epoch 2 with validation loss of 0.0013109843694721348\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "***** Epoch No.: 3 *****\n",
            "\n",
            "\n",
            "Train loss: 0.0008756775609565921\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 100%|██████████| 3/3 [58:42<00:00, 1174.01s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Valid loss: 0.001590783386432031\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HhSj2hQvR3RZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "21e92bd4-b4cf-4b8a-9220-98e5f6b539e8"
      },
      "source": [
        "printm()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Gen RAM Free: 10.0 GB  |     Proc size: 4.9 GB\n",
            "GPU RAM Free: 16280MB | Used: 0MB | Util   0% | Total     16280MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JIE7KBUFxNt-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "outputId": "3b974cd0-3bc8-46e3-e5e8-0d80f50bb661"
      },
      "source": [
        "# Plot loss\n",
        "num_epochs = np.arange(len(train_loss_set))\n",
        " \n",
        "fig, ax = plt.subplots(figsize=(10, 5));\n",
        "ax.plot(num_epochs, np.array(train_loss_set), label=\"Train Loss\")\n",
        "ax.plot(num_epochs, np.array(valid_loss_set), 'g-', label=\"Valid Loss\")\n",
        "#ax1.plot(episode_record, lose_record, 'r-', label=\"Lose %\")\n",
        "ax.set_xlabel(\"Number of Epochs\")\n",
        "ax.set_ylabel(\"Loss\")\n",
        "ax.set_title(\"Loss vs Number of Epochs\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Loss vs Number of Epochs')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}